{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e9e08d-00c3-46aa-b725-0b5980f984e5",
   "metadata": {},
   "source": [
    "# Cleaning Effects on Distributions\n",
    "\n",
    "This notebook briefly analyses the effects of the cleaning pipelines on distributions in the Airbnb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95dc8593-c28e-4a43-ab3e-a44f4f34c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "from cleaner import ErrorCleaner\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2f634b-c151-4bb2-b81d-4d0713c16519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_results(dataset_name, model):\n",
    "    results = pd.read_csv(dataset_name + '_' + model + '_results.csv')\n",
    "    \n",
    "    mean_df = results.groupby(['train_cleaning', 'test_cleaning'], as_index = False).mean(numeric_only=True)\n",
    "    mean_df = mean_df.drop(['train_test_split'], axis = 1)\n",
    "\n",
    "    std_df = results.groupby(['train_cleaning', 'test_cleaning'], as_index = False).std(numeric_only=True)\n",
    "    std_df = results.drop(['train_test_split'], axis = 1)\n",
    "\n",
    "    return results, mean_df, std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d9192e-e951-43c9-bcc3-3f3c107d5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_rfr_results, airbnb_rfr_mean_df, airbnb_rfr_std_df = collect_results('airbnb', 'rfr')\n",
    "airbnb_gbr_results, airbnb_gbr_mean_df, airbnb_gbr_std_df = collect_results('airbnb', 'gbr')\n",
    "airbnb_xgb_results, airbnb_xgb_mean_df, airbnb_xgb_std_df = collect_results('airbnb', 'xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e410b9-1b6c-4d48-87e6-b72d506976a6",
   "metadata": {},
   "source": [
    "## Price distribution\n",
    "\n",
    "The following code highlights how the cleaning pipelines can affect the target ('Price') variable's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a7d744-812a-4869-95c2-2fcd729991f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15800\\3421695192.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcleaned_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaning_setup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mcleaned_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mall_cleaned_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_cleaned_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "airbnb_data = pd.read_csv('airbnb_raw.csv')\n",
    "\n",
    "mv_repair_methods = ['delete', 'mean-mode', 'median-mode', 'mode-mode']\n",
    "\n",
    "outlier_detection_methods = ['none', 'SD', 'IQR']\n",
    "outlier_repair_methods = ['mean', 'median', 'mode']\n",
    "\n",
    "duplicate_repair_methods = ['NA', 'key_val']\n",
    "\n",
    "training_list = [mv_repair_methods, outlier_detection_methods, outlier_repair_methods, duplicate_repair_methods]\n",
    "training_combinations = [p for p in itertools.product(*training_list)]\n",
    "\n",
    "cleaning_setups_df = pd.DataFrame(training_combinations, columns =['mv_repair', 'outlier_detection', 'outlier_repair', \n",
    "                'duplicate_repair'])\n",
    "\n",
    "cleaning_setups_df['outlier_repair'].mask(cleaning_setups_df['outlier_detection'] == 'none', 'NA', inplace=True)\n",
    "\n",
    "cleaning_setups_df = cleaning_setups_df.drop_duplicates()\n",
    "\n",
    "cleaning_setups_df = cleaning_setups_df.reset_index()\n",
    "cleaning_setups_df = cleaning_setups_df.drop(['index'], axis = 1)\n",
    "\n",
    "airbnb_data_subset = airbnb_data[['Price', 'latitude', 'longitude']]\n",
    "\n",
    "all_cleaned_dfs = pd.DataFrame(columns = list(cleaning_setups_df.columns) + ['dataset'])\n",
    "\n",
    "for j in range(len(cleaning_setups_df)):\n",
    "    cleaning_setup = cleaning_setups_df.loc[j]\n",
    "\n",
    "    error_cleaner = ErrorCleaner(airbnb_data_subset, cleaning_setup)\n",
    "    cleaned_dataset = error_cleaner.clean_all(['latitude', 'longitude'])\n",
    "\n",
    "    cleaned_df = dict(cleaning_setup)\n",
    "    cleaned_df['dataset'] = cleaned_dataset\n",
    "    \n",
    "    all_cleaned_dfs = all_cleaned_dfs.append(cleaned_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb27822-6173-4e26-82d8-847401c9608a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# MVs deleted, outliers and duplicates unaddressed\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ax \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mhistplot(all_cleaned_dfs\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mPrice\u001b[38;5;241m.\u001b[39mvalues, bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, element \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mset_size(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# MVs deleted, outliers and duplicates unaddressed\n",
    "ax = sns.histplot(all_cleaned_dfs.dataset.loc[0].Price.values, bins = 100, element = 'step')\n",
    "ax.set(xlabel='Price', ylabel='Count')\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17378035-f0f6-4f80-9a41-ad01e0c24a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values filled with mean, outliers detected using standard deviation and replaced with mean, duplicates unaddressed\n",
    "ax = sns.histplot(all_cleaned_dfs.dataset.loc[16].Price.values, bins = 100, element = 'step')\n",
    "ax.set(xlabel='Price', ylabel='Count')\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a2c85-c055-4753-b4cf-bf59e97fbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVs replaced with median, outliers detected with IQR and replaced with median, duplicates deleted\n",
    "ax = sns.histplot(all_cleaned_dfs.dataset.loc[39].Price.values, bins = 100, element = 'step')\n",
    "ax.set(xlabel='Price', ylabel='Count')\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8f619-f659-4dab-a2df-224b3bbdbcfd",
   "metadata": {},
   "source": [
    "## Differences in Distributions\n",
    "\n",
    "The following code shows the differences in variable distributions (based on Jensen Shannon distance) that can arise through different training and test cleaning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4534d89-31ef-4564-91b2-272dbfa91d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_calc(columns, training_df, test_df):\n",
    "    dist_dic = {}\n",
    "    for column in columns:\n",
    "        training_vals = training_df[column].values\n",
    "        test_vals = test_df[column].values\n",
    "\n",
    "        testing_dist,bins_numpy = np.histogram(test_vals,bins=100)\n",
    "        training_dist,bins2 = np.histogram(training_vals,bins=bins_numpy)\n",
    "    \n",
    "        js_dist = jensenshannon(testing_dist,training_dist)\n",
    "\n",
    "        dist_dic = dist_dic | {column:js_dist}\n",
    "    return dist_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16028b-ed3e-4664-80cb-c94a3a03a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_test = ['Price', 'NumReviews', 'cost_living_index (US avg. = 100)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c6e5a-b76d-444e-a45b-5cf9f1211682",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_distances_df = pd.DataFrame(columns=['train_test_split', 'training_pipeline', 'test_pipeline'] + columns_to_test)\n",
    "\n",
    "for train_test_split in range(20):\n",
    "    all_training_data = pd.read_pickle('airbnb_cleaned_train_df_' + str(train_test_split) + '.pkl')\n",
    "    all_testing_data = pd.read_pickle('airbnb_cleaned_test_df_' + str(train_test_split) + '.pkl')\n",
    "\n",
    "    for i in range(len(all_training_data)):\n",
    "        training_df = all_training_data.dataset.loc[i]\n",
    "        \n",
    "        for j in range(len(all_testing_data)):\n",
    "            test_df = all_testing_data.dataset.loc[j]\n",
    "        \n",
    "            dist_dict = dist_calc(columns_to_test, training_df, test_df)\n",
    "\n",
    "            distribution_distances_df = distribution_distances_df.append({'train_test_split': train_test_split, \n",
    "                                                                          'training_pipeline': i, 'test_pipeline': j} | dist_dict,\n",
    "                                                                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec465b-fb6f-46df-90b7-6bd18522bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution_distances_df.to_csv('cleaning_effects_distributions.csv')\n",
    "distribution_distances_df = pd.read_csv('cleaning_effects_distributions.csv')\n",
    "distribution_distances_df = distribution_distances_df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2d253-bb0a-45fd-b395-25247ad09dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_distances_df['average_dist'] = distribution_distances_df[['Price', 'NumReviews', 'cost_living_index (US avg. = 100)']].mean(axis=1)\n",
    "distribution_distances_df = distribution_distances_df.groupby(['training_pipeline', 'test_pipeline']).mean().reset_index()\n",
    "distribution_distances_df = distribution_distances_df.drop(['train_test_split'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588bff6-7dd4-4093-ac09-31bd3d923486",
   "metadata": {},
   "source": [
    "#### Training cleaning pipelines that minimise distribution differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a35167-fcbf-4ebf-a074-7c7dc3a1c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using target variable only\n",
    "distribution_distances_df.groupby(['training_pipeline']).mean().sort_values('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631855c4-f8a6-4f08-90d3-cd6bb094d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using target plus features\n",
    "distribution_distances_df.groupby(['training_pipeline']).mean().sort_values('average_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc15c74-3685-49bf-b63f-ec67b4954b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing training pipelines for model performance\n",
    "airbnb_rfr_mean_df.groupby(['train_cleaning']).mean().sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4203ab-35e1-41f8-93b6-6c6ddea39b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_gbr_mean_df.groupby(['train_cleaning']).mean().sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6c59b-ef71-4483-aba4-a450bfd637e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_xgb_mean_df.groupby(['train_cleaning']).mean().sort_values('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38670792-e5fc-452b-82d3-5fcab455b1c9",
   "metadata": {},
   "source": [
    "#### Best training pipelines for given test pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ff80c-3893-492f-a32f-17b51b9c6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using target variable only\n",
    "best_training = distribution_distances_df.loc[distribution_distances_df.groupby('test_pipeline').Price.idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c4914-4351-42f5-9c1e-4959a920009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training.loc[best_training.training_pipeline == best_training.test_pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31806a-01b5-41d2-8883-7c58987ff3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(best_training.training_pipeline.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e2f23-0cec-480e-9681-013cfa1f4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(best_training.training_pipeline.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02852d8a-f08e-4e38-abdc-7386dfffb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using target plus features\n",
    "best_training = distribution_distances_df.loc[distribution_distances_df.groupby('test_pipeline').average_dist.idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef30c6b-b5f4-497a-84c8-9f05540ad325",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training.loc[best_training.training_pipeline == best_training.test_pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8f518-0148-4a25-9b6f-02aef74224a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(best_training.training_pipeline.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f38c55-ce8b-4374-bcb9-875c9c75baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(best_training.training_pipeline.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38839d-f4c0-4a00-b066-462e083f2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipelines for model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfa0dc-16dd-4b5b-bdf3-cc09e5403a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines = airbnb_rfr_mean_df.loc[airbnb_rfr_mean_df.groupby('test_cleaning')['score'].idxmax()]\n",
    "np.unique(best_pipelines.train_cleaning.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0e12c-4848-4a75-8a87-9850cf16a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines = airbnb_gbr_mean_df.loc[airbnb_gbr_mean_df.groupby('test_cleaning')['score'].idxmax()]\n",
    "np.unique(best_pipelines.train_cleaning.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befe383-e562-46e4-b6b0-54bba59ee965",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipelines = airbnb_xgb_mean_df.loc[airbnb_xgb_mean_df.groupby('test_cleaning')['score'].idxmax()]\n",
    "np.unique(best_pipelines.train_cleaning.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
